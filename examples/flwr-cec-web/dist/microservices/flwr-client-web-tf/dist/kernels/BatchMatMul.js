/*! For license information please see BatchMatMul.js.LICENSE.txt */
import{BatchMatMul,broadcast_util,util}from"@tensorflow/tfjs-core";import{reshape}from"./Reshape";let wasmBatchMatMul;function setup(a){wasmBatchMatMul=a.wasm.cwrap(BatchMatMul,null,["number","array","number","number","array","number","number","number","number"])}function batchMatMul(a){const{inputs:e,backend:t,attrs:s}=a,{a:n,b:r}=e,{transposeA:p,transposeB:h}=s;if("float32"!==n.dtype||"float32"!==r.dtype)throw new Error("BatchMatMul for non non-float32 tensors not yet supported.");const u=n.shape.length,o=r.shape.length,d=p?n.shape[u-2]:n.shape[u-1],c=h?r.shape[o-1]:r.shape[o-2],l=p?n.shape[u-1]:n.shape[u-2],i=h?r.shape[o-2]:r.shape[o-1],m=n.shape.slice(0,-2),M=r.shape.slice(0,-2),b=util.sizeFromShape(m),f=util.sizeFromShape(M),w=broadcast_util.assertAndGetBroadcastShape(n.shape.slice(0,-2),r.shape.slice(0,-2)).concat([l,i]);util.assert(d===c,(()=>`Error in matMul: inner shapes (${d}) and (${c}) of Tensors with shapes ${n.shape} and ${r.shape} and transposeA=${p} and transposeB=${h} must match.`));const y=h?[f,i,c]:[f,c,i],B=reshape({inputs:{x:n},backend:t,attrs:{shape:p?[b,d,l]:[b,l,d]}}),I=reshape({inputs:{x:r},backend:t,attrs:{shape:y}}),g=t.dataIdMap.get(B.dataId).id,k=t.dataIdMap.get(I.dataId).id,A=p?B.shape[2]:B.shape[1],$=h?I.shape[1]:I.shape[2],x=Math.max(b,f),F=t.makeOutput([x,A,$],B.dtype),S=t.dataIdMap.get(F.dataId).id,z=new Uint8Array(new Int32Array(B.shape).buffer),D=new Uint8Array(new Int32Array(I.shape).buffer);return wasmBatchMatMul(g,z,B.shape.length,k,D,I.shape.length,p,h,S),t.disposeData(B.dataId),t.disposeData(I.dataId),F.shape=w,F}export const batchMatMulConfig={kernelName:BatchMatMul,backendName:"wasm",setupFunc:setup,kernelFunc:batchMatMul};